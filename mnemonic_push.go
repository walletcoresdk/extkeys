package extkeys

import (
	"crypto/rand"
	"crypto/sha256"
	"encoding/binary"
	"math/big"
	"strings"
)

// MnemonicPhrase returns a human readable seed for BIP32 Hierarchical Deterministic Wallets
func (m *Mnemonic) MnemonicPhrasePush(strength EntropyStrength, language Language) (string, error) {
	wordList, err := m.WordList(language)
	if err != nil {
		return "", err
	}

	// The mnemonic must encode entropy in a multiple of 32 bits.
	// With more entropy security is improved but the sentence length increases.
	// We refer to the initial entropy length as ENT. The recommended size of ENT is 128-256 bits.

	if strength%32 > 0 || strength < 128 || strength > 256 {
		return "", ErrInvalidEntropyStrength
	}

	// First, an initial entropy of ENT bits is generated
	entropy := make([]byte, strength/8)
	_, err = rand.Read(entropy)

	if err != nil {
		return "", err
	}

	entropyBigInt := new(big.Int).SetBytes(entropy)

	/*
		首先，生成 ENT 位的初始熵。校验和是通过取第一个
		其 SHA256 哈希的位。该校验和附加到初始熵的末尾。接下来，这些连接的位被分成 11 位的组，每个位编码一个 0-2047 的数字，作为单词列表的索引。最后，我们将这些数字转化为单词，将连接起来的单词作为助记词。
		下表描述了初始熵长度（ENT）、校验和长度（CS）和生成的助记词长度（MS）之间的关系。
	*/
	// A checksum is generated by taking the first bits of its SHA256 hash ( ENT / 32 )
	// This checksum is appended to the end of the initial entropy.
	hash := sha256.Sum256(entropy)
	checksumBitLength := uint(strength / 32)
	sentenceLength := int((uint(strength) + checksumBitLength) / 11)
	words := make([]string, sentenceLength)
	wordSeperator := " "

	switch language {
	case JapaneseLanguage:
		wordSeperator = "　"
	}

	log.Debug(entropy, checksumBitLength, sentenceLength)

	// For each bit of check sum we want we shift the data one the left
	// and then set the (new) right most bit equal to checksum bit at that index
	// starting from the left
	// TODO simplify?
	for i := uint(0); i < checksumBitLength; i++ {
		// Bitshift 1 left
		entropyBigInt.Mul(entropyBigInt, bigTwo)

		// Set rightmost bit if leftmost checksum bit is set
		if uint8(hash[0]&(1<<(7-i))) > 0 { // nolint: unconvert
			entropyBigInt.Or(entropyBigInt, bigOne)
		}
	}

	word := big.NewInt(0)

	bytes := []byte{0x12, 0x34} // 0x1234
	log.Debug(bytes)
	log.Debugf("%x", bytes)
	for i := sentenceLength - 1; i >= 0; i-- {
		// Next, these concatenated bits are split into groups of 11 bits,
		// each encoding a number from 0-2047, serving as an index into a wordlist.

		// Get 11 right most bits and bitshift 11 to the right for next time
		word.And(entropyBigInt, last11BitsMask)
		entropyBigInt.Div(entropyBigInt, rightShift11BitsDivider)

		// Get the bytes representing the 11 bits as a 2 byte slice
		wordBytes := padByteSlice(word.Bytes(), 2)
		log.Debug(i, wordBytes, binary.BigEndian.Uint16(wordBytes))
		log.Debugf("%+v", words)
		// Finally, we convert these numbers into words and
		// use the joined words as a mnemonic sentence.
		words[i] = wordList[binary.BigEndian.Uint16(wordBytes)]
	}

	return strings.Join(words, wordSeperator), nil
}

// 479,001,600
